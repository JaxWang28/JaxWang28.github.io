<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KernelSynchronization on Jackson Blog</title>
    <link>https://blog.jaxwang.top/tags/kernelsynchronization/</link>
    <description>Recent content in KernelSynchronization on Jackson Blog</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 20 May 2025 20:37:06 +0800</lastBuildDate>
    <atom:link href="https://blog.jaxwang.top/tags/kernelsynchronization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Linux Kernel 内核同步之 RCU</title>
      <link>https://blog.jaxwang.top/p/linux-kernel-synchronization-rcu/</link>
      <pubDate>Tue, 20 May 2025 20:37:06 +0800</pubDate>
      <guid>https://blog.jaxwang.top/p/linux-kernel-synchronization-rcu/</guid>
      <description>&lt;h1 id=&#34;linux-kernel-内核同步之-rcu&#34;&gt;Linux Kernel 内核同步之 RCU&lt;/h1&gt;&#xA;&lt;p&gt;尽管 &lt;code&gt;rwlock&lt;/code&gt; 相对于 &lt;code&gt;spinlock&lt;/code&gt; 做了很大的改进，&lt;code&gt;rwlock&lt;/code&gt; 允许多个读者同时并发访问。但是进行写操作时，仅有一个写者具有访问权限，读者不可访问。&lt;code&gt;RCU&lt;/code&gt; 进一步改善了这个问题，其允许多个读者和写者并发执行。而且 &lt;code&gt;RCU&lt;/code&gt; 是不使用锁的，其对读者几乎没有限制，访问效率极高。本文简单概述这项技术。&lt;/p&gt;&#xA;&lt;h2 id=&#34;一rcu-概念理解&#34;&gt;一、RCU 概念理解&lt;/h2&gt;&#xA;&lt;p&gt;以下面的情景引出 RCU 。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;假设你写好一份作业，某一时刻同学A 找到你想借鉴一下你的作业，你把作业放在桌子上让同学A 借鉴。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;没过几分钟（同学A 还在借鉴 :) ），同学B 也来找到你，也想借鉴你一下你的作业，你指了指正在借鉴作业的同学A，说：“过去吧，你们两一起借鉴。”&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;突然，你发现你的作业错写了一步，同学A 和同学B 正在借鉴（读操作）你的作业，此时你又没法修改（不可打断同学A 和同学B，也不能他们读的同时你修改）。怎么办？&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;你以迅雷不及掩耳之势拿出一张A4纸（假设本次作业就是一张 A4纸），copy 原作页并开始改正。好巧不巧，此时同学C 又来借鉴你的作业了，而你此时还没改完，怎么办？那只好和同学A 同学B 一起去借鉴你的原作业。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;终于，你改正完了，此时你拥有了一份新的作业，原来那份就报废了（当然现在还不行，因为同学ABC 还在借鉴）。这时，同学D 也来了，想借鉴你的作业，这时你不能再让他借鉴你的旧作业了。你大方的指了指你的新作业。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;过了一会，同学ABC 都已经借鉴完你的旧作业了（虽然旧作业是有误的，但是你没责任提醒他们）。你发现已经没有同学借鉴你的旧作业了，你就可以把就作业销毁了。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;以上就是一个 RCU 的过程。从上面我们发现，都是以&lt;strong&gt;你&lt;/strong&gt;为中心，而不是你的作业。因此你可以拥有一份新的作业的同时暂时不销毁旧作业。你就像一个指针，指向一份作业。在拥有新作业的同时（malloc），而暂时不销毁旧作业（free）。这也就是为什么&lt;strong&gt;RCU 只保护被动态分配并且通过指针引用的数据结构&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;二rcu-5-core-apis&#34;&gt;二、RCU 5 core APIs&lt;/h2&gt;&#xA;&lt;p&gt;The core RCU API is quite small:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Updateer &lt;code&gt;rcu_assign_pointer&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  1 struct foo {&#xA;  2   int a;&#xA;  3   int b;&#xA;  4   int c;&#xA;  5 };&#xA;  6 struct foo *gp = NULL;&#xA;  7 &#xA;  8 /* . . . */&#xA;  9 &#xA; 10 p = kmalloc(sizeof(*p), GFP_KERNEL);&#xA; 11 p-&amp;gt;a = 1;&#xA; 12 p-&amp;gt;b = 2;&#xA; 13 p-&amp;gt;c = 3;&#xA; 14 gp = p;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据优化和内存屏障部分我们知道 11 12 13 14 行代码不一定按照我们想要的顺序执行，其很有可能先执行 14 行，再依次赋值。因此我们需要内存和优化屏障。Linux Kernel 已经封装了 &lt;code&gt;rcu_assign_pointer&lt;/code&gt; 帮我们实现上述过程。其能保证下面代码先赋值 abc 结束后，再对 gp 赋值。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux Kernel 内核同步之自旋锁</title>
      <link>https://blog.jaxwang.top/p/linux-kernel-synchronization-spinlock/</link>
      <pubDate>Mon, 19 May 2025 22:37:06 +0800</pubDate>
      <guid>https://blog.jaxwang.top/p/linux-kernel-synchronization-spinlock/</guid>
      <description>&lt;h1 id=&#34;linux-kernel-内核同步之自旋锁&#34;&gt;Linux Kernel 内核同步之自旋锁&lt;/h1&gt;&#xA;&lt;p&gt;加锁（locking）是一种广泛应用的同步技术。当要访问&lt;strong&gt;共享数据结构&lt;/strong&gt;或进入&lt;strong&gt;临界区&lt;/strong&gt;时，为自己获得一把“锁”，离开时再释放锁。在获得锁到释放锁之间的之短时间内是禁止其他 CPU 访问的。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;spin_lock(&amp;amp;lock);&#xA;...&#xA;spin_unlock(&amp;amp;lock);&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不同系统架构的自旋锁实现是不同的：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;不支持内核抢占的单处理器：自旋锁的实现是空的&lt;/li&gt;&#xA;&lt;li&gt;支持内核抢占的单处理器：自旋锁的实现仅仅是禁止或启用&lt;strong&gt;内核抢占&lt;/strong&gt;。参考下面例子：&#xA;&lt;ol&gt;&#xA;&lt;li&gt;线程 A 获得锁&lt;/li&gt;&#xA;&lt;li&gt;线程 B 抢占内核获得执行权&lt;/li&gt;&#xA;&lt;li&gt;线程 B 获取相同锁发现已被锁&lt;/li&gt;&#xA;&lt;li&gt;. 线程 B 的优先级高于线程 A，死锁&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;支持内核抢占的多处理器：需要完整实现自旋锁&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;spin_lock&lt;/code&gt; 是不会禁用&lt;strong&gt;本地中断&lt;/strong&gt;的，但是提供了 &lt;code&gt;spin_lock_irq&lt;/code&gt; ，其不仅会禁用内核抢占并且会禁用本地中断。当需要上锁的共享资源会在中断处理中被访问，我们需要使用禁止本地中断的锁，原因如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;线程 A 获得锁&lt;/li&gt;&#xA;&lt;li&gt;触发中断，中断处理中要获得相同锁，死锁&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;spin_lock_irq()&lt;/code&gt; 在任何情况下都是安全的，但是没有 &lt;code&gt;spin_lock()&lt;/code&gt; 快。[3]&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;代数&lt;/th&gt;&#xA;          &lt;th&gt;名称&lt;/th&gt;&#xA;          &lt;th&gt;内核版本&lt;/th&gt;&#xA;          &lt;th&gt;公平性&lt;/th&gt;&#xA;          &lt;th&gt;高效性&lt;/th&gt;&#xA;          &lt;th&gt;接口兼容性&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;第一代&lt;/td&gt;&#xA;          &lt;td&gt;原始自旋锁&lt;/td&gt;&#xA;          &lt;td&gt;1.0 - 2.6.24&lt;/td&gt;&#xA;          &lt;td&gt;不公平&lt;/td&gt;&#xA;          &lt;td&gt;不高效&lt;/td&gt;&#xA;          &lt;td&gt;兼容&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;第二代&lt;/td&gt;&#xA;          &lt;td&gt;ticket spinlock&lt;/td&gt;&#xA;          &lt;td&gt;2.6.25 - 4.1x&lt;/td&gt;&#xA;          &lt;td&gt;公平&lt;/td&gt;&#xA;          &lt;td&gt;不高效&lt;/td&gt;&#xA;          &lt;td&gt;兼容&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;第三代&lt;/td&gt;&#xA;          &lt;td&gt;MCS spinlock&lt;/td&gt;&#xA;          &lt;td&gt;3.15 - now&lt;/td&gt;&#xA;          &lt;td&gt;公平&lt;/td&gt;&#xA;          &lt;td&gt;高效&lt;/td&gt;&#xA;          &lt;td&gt;不兼容&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;第四代&lt;/td&gt;&#xA;          &lt;td&gt;queued spinlock&lt;/td&gt;&#xA;          &lt;td&gt;4.2 - now&lt;/td&gt;&#xA;          &lt;td&gt;公平&lt;/td&gt;&#xA;          &lt;td&gt;高效&lt;/td&gt;&#xA;          &lt;td&gt;兼容&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;自旋锁首次提出之后又经历了三次迭代，下面对其简述：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux Kernel 内核同步之优化和内存屏障</title>
      <link>https://blog.jaxwang.top/p/linux-kernel-synchronization-optimization-memory-barriers/</link>
      <pubDate>Mon, 19 May 2025 20:37:06 +0800</pubDate>
      <guid>https://blog.jaxwang.top/p/linux-kernel-synchronization-optimization-memory-barriers/</guid>
      <description>&lt;h1 id=&#34;linux-kernel-内核同步之优化和内存屏障&#34;&gt;Linux Kernel 内核同步之优化和内存屏障&lt;/h1&gt;&#xA;&lt;p&gt;Linux Kernel 是支持优化屏障和内存屏障的，其中优化屏障是针对&lt;strong&gt;编译器&lt;/strong&gt;而言的，内存屏障是针对&lt;strong&gt;处理器&lt;/strong&gt;而言的，因此内存屏障取决于处理器架构。本文以 &lt;code&gt;ARMv8&lt;/code&gt; 架构处理器从下向上讲解内存屏障，并简述优化屏障。&lt;/p&gt;&#xA;&lt;h2 id=&#34;一linux-kernel-优化屏障&#34;&gt;一、Linux Kernel 优化屏障&lt;/h2&gt;&#xA;&lt;p&gt;编译器在编译源代码时会考虑性能进行优化重新排序指令顺序，以下面代码为例：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;volatile int a = 0;&#xA;volatile int b = 0;&#xA;&#xA;void no_barrier() {&#xA;    a = 1;&#xA;    b = 2;&#xA;}&#xA;&#xA;void with_barrier() {&#xA;    a = 1;&#xA;    asm volatile(&amp;#34;&amp;#34; ::: &amp;#34;memory&amp;#34;);  // 编译器优化屏障&#xA;    b = 2;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;aarch64-none-linux-gnu-gcc -S test.c -O3  -o test.s&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;no_barrier:&#xA;.LFB0:&#xA;        .cfi_startproc&#xA;        adrp    x0, .LANCHOR0&#xA;        add     x1, x0, :lo12:.LANCHOR0&#xA;        mov     w3, 1&#xA;        mov     w2, 2&#xA;        str     w3, [x0, #:lo12:.LANCHOR0]&#xA;        str     w2, [x1, 4]&#xA;        ret&#xA;        .cfi_endproc&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;with_barrier:&#xA;.LFB1:&#xA;        .cfi_startproc&#xA;        adrp    x0, .LANCHOR0&#xA;        mov     w2, 1&#xA;        add     x1, x0, :lo12:.LANCHOR0&#xA;        str     w2, [x0, #:lo12:.LANCHOR0]&#xA;        mov     w0, 2&#xA;        str     w0, [x1, 4]&#xA;        ret&#xA;        .cfi_endproc&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们只需观察 &lt;code&gt;mov&lt;/code&gt; &lt;code&gt;str&lt;/code&gt; 指令的顺序：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux Kernel 内核同步之原子操作</title>
      <link>https://blog.jaxwang.top/p/linux-kernel-synchronization-atomic-operations/</link>
      <pubDate>Sun, 18 May 2025 21:37:06 +0800</pubDate>
      <guid>https://blog.jaxwang.top/p/linux-kernel-synchronization-atomic-operations/</guid>
      <description>&lt;h1 id=&#34;linux-kernel-内核同步之原子操作&#34;&gt;Linux Kernel 内核同步之原子操作&lt;/h1&gt;&#xA;&lt;p&gt;原子操作是指指令以原子的方式执行，执行过程不会被打断。要保证操作的原子性和完整性，需要“原子地”（不间断地）完整&lt;strong&gt;读-修改-回写&lt;/strong&gt;机制。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;static int i = 0;&#xA;void thread_A _func()&#xA;{&#xA;&#x9;i++;&#xA;}&#xA;void thread_B _func()&#xA;{&#xA;&#x9;i++;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面代码的理想执行结果是&lt;code&gt;i&lt;/code&gt; 为 2，但事实并非如此， i 有一定的概率为 1。对于 &lt;code&gt;thread_A&lt;/code&gt; 和 &lt;code&gt;thread_B&lt;/code&gt; 进行的操作可以简单理解为：&lt;strong&gt;读 - 修改 - 回写&lt;/strong&gt;。从单处理器和多处理器角度分析：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;单处理器：&lt;code&gt;thread_A&lt;/code&gt; 与 &lt;code&gt;thread_B&lt;/code&gt; 存在并发，当 &lt;code&gt;thread_A&lt;/code&gt; 执行完 &lt;code&gt;读&lt;/code&gt; 操作，CPU 有可能切换为 &lt;code&gt;thread_B&lt;/code&gt; 执行 &lt;code&gt;读&lt;/code&gt; 操作，这样最终的结果为 1.&lt;/li&gt;&#xA;&lt;li&gt;多处理器：&lt;code&gt;thread_A&lt;/code&gt; 与 &lt;code&gt;thread_B&lt;/code&gt; 存在并发，&lt;code&gt;thread_A&lt;/code&gt; 与 &lt;code&gt;thread_B&lt;/code&gt; 可能同时执行 &lt;code&gt;读&lt;/code&gt; 操作，这样最终结果也为 1.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;因此，要想保证结果的正确性，我们必须保证上面的操作完整地原子地（不间断地）完成&lt;strong&gt;读-修改-回写&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;原子操作是以硬件为基础，即 &lt;strong&gt;CPU 必须提供原子操作的汇编指令&lt;/strong&gt;。本文以 ARMv8 架构为例从下至上分析原子操作。&lt;/p&gt;&#xA;&lt;h2 id=&#34;一arm64-原子操作&#34;&gt;一、ARM64 原子操作&lt;/h2&gt;&#xA;&lt;p&gt;原子操作需要处理器提供硬件支持，ARMv8 提供两种方式实现了原子操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;独占内存访问指令：独占加载（Load-Exclusive）和独占存储（Store-Exclusive）指令，其实现方式叫做连接加载/条件存储（Load-Link/Store-Conditional, LL/SC）&lt;/li&gt;&#xA;&lt;li&gt;原子内存访问指令：ARMv8.1 体系实现的 LSE 指令&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;em&gt;本文不对这两种方式详细展开，感兴趣的可以阅读 References[2] 书籍。&lt;/em&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
