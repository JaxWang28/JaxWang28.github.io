<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <title>Linux Kernel 内核同步之自旋锁</title>
    <meta name="description" content="Linux Kernel 内核同步之自旋锁">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link rel="stylesheet" href="/css/github-markdown-light.css" />
    
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
    <link rel="manifest" href="/favicon/site.webmanifest">

  </head>

  <body>
    <nav>
      <ul class="menu">
        
        <li><a href="/">Home</a></li>
        
        <li><a href="/post/">Posts</a></li>
        
        <li><a href="/categories/">Categories</a></li>
        
        <li><a href="/tags/">Tags</a></li>
        
        <li><a href="/about/">About</a></li>
        
        <li><a href="/bookshelf">Bookshelf</a></li>
        
        <li><a href="/index.xml">RSS</a></li>
        
      </ul>
      <hr/>
    </nav>

<div style="margin-left: auto; margin-right: 0; text-align: right;" >
  📅
   2025/05/19 
</div>
<div class="markdown-box">
<main class="markdown-body">
<h1 id="linux-kernel-内核同步之自旋锁">Linux Kernel 内核同步之自旋锁</h1>
<p>加锁（locking）是一种广泛应用的同步技术。当要访问<strong>共享数据结构</strong>或进入<strong>临界区</strong>时，为自己获得一把“锁”，离开时再释放锁。在获得锁到释放锁之间的之短时间内是禁止其他 CPU 访问的。</p>
<pre tabindex="0"><code>spin_lock(&amp;lock);
...
spin_unlock(&amp;lock);
</code></pre><p>不同系统架构的自旋锁实现是不同的：</p>
<ol>
<li>不支持内核抢占的单处理器：自旋锁的实现是空的</li>
<li>支持内核抢占的单处理器：自旋锁的实现仅仅是禁止或启用<strong>内核抢占</strong>。参考下面例子：
<ol>
<li>线程 A 获得锁</li>
<li>线程 B 抢占内核获得执行权</li>
<li>线程 B 获取相同锁发现已被锁</li>
<li>. 线程 B 的优先级高于线程 A，死锁</li>
</ol>
</li>
<li>支持内核抢占的多处理器：需要完整实现自旋锁</li>
</ol>
<p><code>spin_lock</code> 是不会禁用<strong>本地中断</strong>的，但是提供了 <code>spin_lock_irq</code> ，其不仅会禁用内核抢占并且会禁用本地中断。当需要上锁的共享资源会在中断处理中被访问，我们需要使用禁止本地中断的锁，原因如下：</p>
<ol>
<li>线程 A 获得锁</li>
<li>触发中断，中断处理中要获得相同锁，死锁</li>
</ol>
<p><code>spin_lock_irq()</code> 在任何情况下都是安全的，但是没有 <code>spin_lock()</code> 快。[3]</p>
<table>
  <thead>
      <tr>
          <th>代数</th>
          <th>名称</th>
          <th>内核版本</th>
          <th>公平性</th>
          <th>高效性</th>
          <th>接口兼容性</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>第一代</td>
          <td>原始自旋锁</td>
          <td>1.0 - 2.6.24</td>
          <td>不公平</td>
          <td>不高效</td>
          <td>兼容</td>
      </tr>
      <tr>
          <td>第二代</td>
          <td>ticket spinlock</td>
          <td>2.6.25 - 4.1x</td>
          <td>公平</td>
          <td>不高效</td>
          <td>兼容</td>
      </tr>
      <tr>
          <td>第三代</td>
          <td>MCS spinlock</td>
          <td>3.15 - now</td>
          <td>公平</td>
          <td>高效</td>
          <td>不兼容</td>
      </tr>
      <tr>
          <td>第四代</td>
          <td>queued spinlock</td>
          <td>4.2 - now</td>
          <td>公平</td>
          <td>高效</td>
          <td>兼容</td>
      </tr>
  </tbody>
</table>
<p>自旋锁首次提出之后又经历了三次迭代，下面对其简述：</p>
<ol>
<li>第一代原始自旋锁，对于等待锁的 CPU 只是无脑的“盲等”（尽管等待锁时时没有禁用内核抢占，可以调度执行其他任务），其不具有公平性，即没有先后顺序。</li>
<li>第二代 ticket spinlock，其具有公平性，但是不高效。</li>
</ol>
<p>对于 ARM64 已经不支持第一代和第二代 spinlock , 本文着重讲解 MCS spinlock 和 queued spinlock。</p>
<pre tabindex="0"><code>commit c11090474d70590170cf5fa6afe85864ab494b37
Author: Will Deacon &lt;will@kernel.org&gt;
Date:   Tue Mar 13 20:45:45 2018 +0000

    arm64: locking: Replace ticket lock implementation with qspinlock

    It&#39;s fair to say that our ticket lock has served us well over time, but
    it&#39;s time to bite the bullet and start using the generic qspinlock code
    so we can make use of explicit MCS queuing and potentially better PV
</code></pre><h2 id="一spinlock-apis">一、spinlock APIs</h2>
<table>
  <thead>
      <tr>
          <th>API</th>
          <th>功能</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>spin_lock(&amp;lock)</td>
          <td>获取自旋锁</td>
      </tr>
      <tr>
          <td>spin_unlock(&amp;lock)</td>
          <td>释放自旋锁</td>
      </tr>
      <tr>
          <td>spin_trylock(&amp;lock)</td>
          <td>尝试获取锁，成功返回 true</td>
      </tr>
      <tr>
          <td>spin_is_locked(&amp;lock)</td>
          <td>检查锁是否被持有</td>
      </tr>
      <tr>
          <td>spin_unlock_wait(&amp;lock)</td>
          <td>等待锁释放，不加锁</td>
      </tr>
      <tr>
          <td>spin_lock_irq(&amp;lock)</td>
          <td>获取锁 + 禁用本地 CPU 的中断</td>
      </tr>
      <tr>
          <td>spin_unlock_irq(&amp;lock)</td>
          <td>解锁 + 恢复中断</td>
      </tr>
      <tr>
          <td>spin_lock_irqsave(&amp;lock, flags)</td>
          <td>获取锁 + 保存当前中断状态 + 禁用中断</td>
      </tr>
      <tr>
          <td>spin_unlock_irqrestore(&amp;lock, flags)</td>
          <td>解锁 + 恢复之前的中断状态</td>
      </tr>
      <tr>
          <td>spin_lock_bh(&amp;lock)</td>
          <td>取锁 + 禁用软中断</td>
      </tr>
  </tbody>
</table>
<h2 id="二mcs-spinlock">二、MCS spinlock</h2>
<p>ticket spinlock 完美解决了公平问题，但是存在一个问题，就是当锁竞争比较激烈的时候，大家都在自旋同一个变量，造成 <strong>多核频繁竞争同一个缓存行</strong>，引发 <strong>缓存颠簸</strong>，进而拖慢整个系统的同步效率。为了解决这个问题，设计出一种锁，把所有排队等锁的线程放到一个队列上，每个线程自选<strong>自己的节点</strong>，因为是队列，还是一个公平锁。</p>
<p>其算法如下：</p>
<ol>
<li>自旋锁是一个指针初始化为 <code>NULL</code>，如图中时刻 1</li>
<li>当线程取锁时，先生成一个锁<code>locked=0 next=NULL</code>，检查自旋锁指针：
<ol>
<li>若自旋锁指针为 <code>NULL</code> ，则此前没人获得锁，将自旋锁指针指向自己的锁。如图中时刻 2</li>
<li>若自旋锁指针不为 <code>NULL</code>，则该锁已被获得，将此时自旋锁指向的锁的 <code>next</code> 指向自己，并更新自选锁指针也为自己的锁。然后自选变量 <code>locked</code> 直至为 1，如图中时刻 3</li>
</ol>
</li>
<li>当线程释放锁时：
<ol>
<li>若 <code>next</code> 不为 <code>NULL</code>，则将 <code>next-&gt;locket</code> 置为 <code>1</code>。如图中时刻 4。</li>
<li>若 <code>next</code> 为 <code>NULL</code>，则将自旋锁变量置为 <code>NULL</code></li>
</ol>
</li>
</ol>
<p><img src="https://img.jaxwang.top/2025/05/2633c01cacf10dc09abfdfb4706f9b18.png" alt=""></p>
<pre tabindex="0"><code>static inline
void mcs_spin_lock(struct mcs_spinlock **lock, struct mcs_spinlock *node)
{
	struct mcs_spinlock *prev;

	/* Init node */
	node-&gt;locked = 0;
	node-&gt;next   = NULL;

	prev = xchg(lock, node);     // 每次获得锁都会先将自旋锁指针指向新的锁节点
	if (likely(prev == NULL)) {  // 上述 2.1 为 NULL 直接获得锁
		return;
	}
	WRITE_ONCE(prev-&gt;next, node);

	/* Wait until the lock holder passes the lock down. */
	arch_mcs_spin_lock_contended(&amp;node-&gt;locked);   // 上述 2.2 自旋直至 locked=1
}
</code></pre><h2 id="三queued-spinlock">三、queued spinlock</h2>
<p>MCS 锁有一个很大的问题就是它改变了自旋锁的接口，这是一个很严重的问题，内核里使用自旋锁的地方很多，如果把自旋锁都改为MCS自旋锁，那将是非常麻烦的。同时MCS还有一个问题就是它的体积增大了，这也是一个很严重的问题。</p>
<p>队列自旋锁对MCS自旋锁的优化原理是，一个系统最多同时有NR_CPU个自旋锁在运行，所以没必要每个加锁线程都自己分配一个锁节点，我们在系统全局预分配NR_CPU个锁节点就可以了，哪个CPU上要执行自旋锁，就去用对应的锁节点就可以了。这是对于只有线程的情况，实际上还有软中断、硬中断、NMI，它们后者都可以抢占前者，都能抢占线程，所以整个系统实际上总共需要 NR_CPU * 4 个锁节点就足够了。</p>
<p><em>TODO 具体算法实现后面再写了。</em></p>
<h2 id="references">References</h2>
<p>[1] 深入理解Linux内核之自旋锁 <a href="https://zhuanlan.zhihu.com/p/584016727">https://zhuanlan.zhihu.com/p/584016727</a></p>
<p>[2] spinlock与中断、抢占的关系 <a href="https://blog.csdn.net/liduxun/article/details/47833143">https://blog.csdn.net/liduxun/article/details/47833143</a></p>
<p>[3] 并发：自旋锁 <a href="https://cslqm.github.io/2020/01/06/spin-lock/">https://cslqm.github.io/2020/01/06/spin-lock/</a></p>

</main>
</div>

<br>

  <footer>
  <hr/>
  
  
  <hr/>
  © <a href="https://jaxwang28.github.io">Jackson Wang</a> 2022 &ndash; 2025 | <a href="https://github.com/jaxwang28">Github</a>
  
  </footer>
  </body>
</html>

